---
layout: post
title: Week 4
---

With a better understanding this week of what I am trying to achieve, I dove back into the literature to learn more about using NLP on search queries. There are a few papers that even discuss querying 3-D mesh databases. <a href="https://www.cs.princeton.edu/~funk/tog03.pdf" target="_blank" rel="noopener noreferrer">Funkerhouser et al.</a> and <a href="https://www.cs.jhu.edu/~misha/MyPapers/WEB3D.pdf" target="_blank" rel="noopener noreferrer">Min et al.</a> both design search approaches that mix text queries with another more visual method. I found reading their text methodologies helpful, and I'm sure it will be even more useful once I move on to mixing text with the segmentation algorithms Faraz has developed.

I wanted to make my algorithm more generalized than the first model I came up with that just looked for 15 predetermined assistive device keywords. Instead of having a predefined list of keywords to extract from file descriptions, I used words from the query as the keywords. This made the preprocessing even more important so I had to implement spaCy's token matching feature instead of the phrase to allow for "fuzzy matching" to catch misspellings (I may wind up needing to switch to NLTK to implement synonym matching as well). I've implemented a rough heuristic to try to match the most important words by weighing nouns more heavily than adjectives and verbs. SpaCy is able to identify these parts of speech for me and has already eliminated "stop words" that are too common to be useful. My mom who is a PT generously supplied me with some sample queries that she would use for assistive devices, and after adjusting the heuristic, my results told me I was headed in the right direction.
